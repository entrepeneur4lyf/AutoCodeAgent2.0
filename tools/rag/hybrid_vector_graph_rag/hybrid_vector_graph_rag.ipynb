{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid Vector Graph RAG\n",
        "\n",
        "Hybrid Vector Graph RAG takes data retrieval to the next level by combining the strengths of vector embeddings and graph databases. This technique not only stores text chunks as vectors but also captures the relationships between them in a graph structure. The result is a powerful tool that can navigate complex data relationships, making it perfect for tasks that require deep contextual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Introduction\n",
        "\n",
        "Hybrid Vector Graph RAG integrates advanced vector embeddings with a graph database (Neo4j) to create a robust system for document retrieval and contextual enrichment. By leveraging summarization and lemmatization techniques alongside a specialized vector store (ChromaDB), the system prepares ingested data for deeper analytical tasks and ensures comprehensive retrieval through advanced search strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Underlying Concept\n",
        "\n",
        "Traditional retrieval-augmented generation systems often retrieve documents in a generic manner without fully accounting for the relationships between text segments. In contrast, Hybrid Vector Graph RAG stores text chunks as vector embeddings and integrates them into a graph structure using Neo4j. This approach captures inherent relationships between data points while employing summarization and lemmatization to normalize content, thereby enriching the context for each query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Components\n",
        "1. **Embedding and Storage Module:**: Utilizes ChromaDB to store text chunks along with their vector embeddings.\n",
        "2. **Graph Database Module:**: Leverages Neo4j to create nodes representing text chunks and to establish similarity edges based on cosine similarity.\n",
        "3. **Text Processing Module:**: Employs SpaCy for text normalization and lemmatization, ensuring consistent analysis of the data.\n",
        "4. **Summarization Module:**: Uses a language model to generate concise summaries of each text chunk, distilling the core content.\n",
        "5. **Retrieval Module:**: Combines initial vector-based retrieval from ChromaDB with a Breadth-First Search (BFS) on the Neo4j graph to compile a rich context for answering queries.\n",
        "6. **File Ingestion Module:**: Processes PDF and TXT files (via dedicated scripts) to extract and format text for ingestion into the system.\n"
      ]
    },    
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How It Works\n",
        "\n",
        "### Ingestion Steps:\n",
        "1. **Start Ingestion:**: Initiates the ingestion process for new data\n",
        "2. **Split Texts into Chunks:**: Breaks large documents into smaller segments based on a maximum character limit and specified overlap to preserve context\n",
        "3. **Create Embeddings for Chunks:**: Converts each text chunk into a numerical vector using a dedicated embedding model\n",
        "4. **Add Documents to ChromaDB:**: Stores the text chunks, their embeddings, and associated metadata in ChromaDB for efficient vector retrieval\n",
        "5. **Summarize Each Chunk:**: Generates a concise summary for each chunk using a language model\n",
        "6. **Lemmatize Summaries:**: Processes the summaries with SpaCy to reduce words to their base forms, ensuring consistency in text analysis\n",
        "7. **Create Lemma Embeddings:**: Converts the lemmatized summaries into embeddings to capture the distilled meaning of the content\n",
        "8. **Create Nodes in Neo4j:**: Inserts the summarized and lemmatized data as nodes in the Neo4j graph database, tagging each with metadata such as a unique corpus label and color\n",
        "9. **Create Similarity Edges:**: Establishes connections between nodes (text chunks) by creating similarity edges when the cosine similarity exceeds a defined threshold\n",
        "10. **End Ingestion:**: Finalizes the ingestion process, ensuring all data is stored and all relationships are properly established\n",
        "\n",
        "### Retrieval Steps:\n",
        "1. **Start Retrieval:**: Initiates the process based on a userâ€™s query\n",
        "2. **Embed User Query:**: Transforms the query into a vector using the same embedding model employed during ingestion\n",
        "3. **Query ChromaDB for Top_k Chunks:**: Retrieves the top k text chunks that are most similar to the query based on vector similarity\n",
        "4. **Initialize BFS with Retrieved Chunks:**: Starts a Breadth-First Search (BFS) in the Neo4j graph using the initially retrieved chunks as the starting nodes\n",
        "5. **Is Context Enough?:**: Uses a language model to determine if the gathered context is sufficient to answer the query; if the context is sufficient, the system proceeds to generate the final answer; if not, BFS expands by exploring neighboring nodes with similarity scores above a threshold\n",
        "6. **Generate Final Answer:**: Compiles all relevant information into a final context and uses a language model to generate a detailed answer\n",
        "7. **Return Final Answer:**: Outputs the generated answer to the user\n",
        "8. **End Retrieval:**: Concludes the retrieval process once a complete answer is formulated or the maximum BFS depth is reached\n"
      ]
    },    
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow Diagram\n",
        "\n",
        "![Hybrid Vector Graph RAG Workflow](./hybrid_vector_graph_rag_workflow.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Advantages\n",
        "\n",
        "- **Graph-Based Relationships:** Captures deep, inherent connections between text chunks using Neo4j.\n",
        "- **Summarization and Lemmatization:** Normalizes and condenses text for more effective comparison and analysis.\n",
        "- **Advanced Retrieval via BFS:** Explores related nodes in the graph to ensure comprehensive context gathering.\n",
        "- **Enhanced Contextual Understanding:** Provides detailed insights by integrating diverse retrieval methods.\n",
        "- **Efficient Storage and Retrieval:** Combines the speed of vector search in ChromaDB with the relational power of graph databases.\n",
        "\n",
        "### Key Features\n",
        "- **Graph-Based Relationships:** Captures and leverages relationships between text chunks using Neo4j, a leading graph database.\n",
        "- **Summarization and Lemmatization:** Summarizes text chunks and reduces words to their base forms for consistent analysis.\n",
        "- **Advanced Retrieval:** Uses Breadth-First Search (BFS) to explore and retrieve related information, ensuring comprehensive context for each query.\n",
        "\n",
        "### Use Cases\n",
        "- Building knowledge graphs from ingested data.\n",
        "- Retrieving information with deep contextual relevance.\n",
        "- Handling complex queries that require understanding of data relationships.\n",
        "\n",
        "### Example Prompt\n",
        "- \"Save the latest research papers on quantum computing in the database using the tool: `ingest_hybrid_vector_graph_rag`.\"\n",
        "- \"Find information about the connections between AI and healthcare using the tool: `retrieve_hybrid_vector_graph_rag`.\"\n",
        "\n",
        "### Bulk Ingestion\n",
        "You can ingest a corpus by directly uploading files in txt or pdf format to the /tools/rag/hybrid_vector_graph_rag/corpus folder.\n",
        "To start the batch processing, simply make an API call:\n",
        "```bash\n",
        "curl -X POST http://localhost:5000/hybrid-vector-graph-rag-ingest-corpus\n",
        "```\n",
        "The script will process the information in the files, transferring it to the vector and graph database.\n",
        "\n",
        "### Neo4j Database Browser\n",
        "Access the Neo4j database browser at [http://localhost:7474/browser/](http://localhost:7474/browser/) and run queries to retrieve, delete or modify the data:\n",
        "```bash\n",
        "MATCH (n:Chunk) RETURN n LIMIT 200\n",
        "```\n",
        "```bash\n",
        "MATCH (n:Chunk) DETACH DELETE n\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical Benefits\n",
        "\n",
        "- **Deep Contextual Insight:** Enables navigation through complex data relationships for richer answers.\n",
        "- **Improved Accuracy:** Tailored retrieval processes yield more precise and contextually relevant responses.\n",
        "- **Knowledge Graph Construction:** Facilitates the creation of interconnected knowledge graphs from ingested data.\n",
        "- **Scalability and Customization:** Adaptable to varying data sizes and specific retrieval requirements.\n",
        "- **Comprehensive Analysis:** Integrates multiple processing steps to ensure that the final answers are complete and insightful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation Insights\n",
        "\n",
        "- **engine.py:** Implements the core logic for the Hybrid Vector Graph RAG system including data ingestion, embedding creation, summarization, lemmatization, Neo4j integration, and BFS-based retrieval with LLM checks.\n",
        "- **ingest_corpus.py:** Handles file extraction and processing (for PDF and TXT formats) and coordinates the ingestion of corpora into the system using the HybridVectorGraphRag class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_CHUNK_SIZE=1500:** Maximum number of characters per text chunk during ingestion.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_OVERLAP=200:** Number of overlapping characters between consecutive chunks to maintain context.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_SUMMARIZATION_GRAPH_NODE_LENGTH=100:** Target word count for generating summaries of text chunks.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_SIMILARITY_RETRIEVE_THRESHOLD=0.9:** Cosine similarity threshold used to retrieve the most relevant chunks from ChromaDB.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_SIMILARITY_EDGE_THRESHOLD=0.9:** Threshold above which similarity edges are created between nodes in Neo4j.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_QUERY_MAX_DEPTH=3:** Maximum depth allowed during BFS traversal in the retrieval process.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_QUERY_TOP_K=3:** Number of top similar chunks retrieved initially from ChromaDB.\n",
        "- **HYBRID_VECTOR_GRAPH_RAG_QUERY_MAX_CONTEXT_LENGTH=10000:** Maximum allowed length of context when compiling information for the final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Hybrid Vector Graph RAG represents an advanced integration of vector embeddings and graph database technologies. The system effectively ingests, processes, and retrieves data using a combination of summarization, lemmatization, and BFS-based retrieval strategies. This approach not only ensures deep contextual understanding and accuracy but also provides a scalable solution for navigating complex data relationships. With its robust architecture and flexible parameters, Hybrid Vector Graph RAG is well-suited for building knowledge graphs, retrieving detailed contextual insights, and handling intricate queries across diverse datasets."
      ]
    }
    
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
